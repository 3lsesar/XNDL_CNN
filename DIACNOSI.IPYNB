{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss acuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suposant que tenim història de l'entrenament en 'history'\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Gràfic de pèrdua d'entrenament\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Gràfic de Pèrdua d\\'Entrenament i Validació')\n",
    "plt.xlabel('Èpoques')\n",
    "plt.ylabel('Pèrdua')\n",
    "plt.legend()\n",
    "\n",
    "# Gràfic de precisió\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('Gràfic de Precisió d\\'Entrenament i Validació')\n",
    "plt.xlabel('Èpoques')\n",
    "plt.ylabel('Precisió')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Suposem que 'test_preds' són les prediccions i 'test_labels' són les etiquetes veritables\n",
    "conf_mat = confusion_matrix(test_labels, test_preds.argmax(axis=1))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=idx_to_label.values(), yticklabels=idx_to_label.values())\n",
    "plt.xlabel('Prediccions')\n",
    "plt.ylabel('Etiquetes Veritables')\n",
    "plt.title('Matriu de Confusió')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_loss_variation(history):\n",
    "    # Calcula la variació de la pèrdua per època\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    train_loss_variation = np.diff(train_loss)\n",
    "    val_loss_variation = np.diff(val_loss)\n",
    "\n",
    "    # Ploteja la variació de la pèrdua\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss_variation, label='Variació de Pèrdua d\\'Entrenament')\n",
    "    plt.xlabel('Èpoques')\n",
    "    plt.ylabel('Variació de la Pèrdua')\n",
    "    plt.title('Variació de la Pèrdua d\\'Entrenament')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_loss_variation, label='Variació de Pèrdua de Validació')\n",
    "    plt.xlabel('Èpoques')\n",
    "    plt.ylabel('Variació de la Pèrdua')\n",
    "    plt.title('Variació de la Pèrdua de Validació')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Suposant que 'history' és l'objecte retornat per la funció fit() de Keras\n",
    "# history = model.fit(...)\n",
    "\n",
    "\n",
    "plot_loss_variation(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def plot_pruned_weights(model):\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense):\n",
    "            # Acceder directamente a los pesos y las máscaras, si existen\n",
    "            weights = layer.get_weights()[0]  # siempre existe como los pesos de la capa\n",
    "            if len(layer.get_weights()) > 1:\n",
    "                # Si hay más de un conjunto de pesos, el segundo conjunto suele ser la máscara\n",
    "                masks = layer.get_weights()[1]\n",
    "                pruned_weights = weights * masks  # Aplicación de la máscara\n",
    "            else:\n",
    "                # Si no hay máscara, trata los pesos originales como los pruned para visualización\n",
    "                pruned_weights = weights\n",
    "\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.hist(weights.flatten(), bins=100)\n",
    "            plt.title(f'Distribución de Pesos Originales en {layer.name}')\n",
    "            plt.xlabel('Valor del Peso')\n",
    "            plt.ylabel('Frecuencia')\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.hist(pruned_weights.flatten(), bins=100)\n",
    "            plt.title(f'Distribución de Pesos Después de Pruning en {layer.name}')\n",
    "            plt.xlabel('Valor del Peso')\n",
    "            plt.ylabel('Frecuencia')\n",
    "            plt.show()\n",
    "\n",
    "# Asumiendo que `model` es tu modelo pruned\n",
    "plot_pruned_weights(model)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
