unload bsc/1.0 (PATH, MANPATH)
load openmpi/4.1.5-gcc (LD_LIBRARY_PATH)
load HDF5/1.14.1-2 (PATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH, HDF5_DIR, HDF5_ROOT) 
load mkl/2024.0 (LD_LIBRARY_PATH)
load PYTHON/3.11.5 (PATH, MANPATH, LD_LIBRARY_PATH, LIBRARY_PATH,
PKG_CONFIG_PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, PYTHONHOME, PYTHONPATH) 
load bsc/1.0 (PATH, MANPATH)
load OPENJDK/11.0.2 (PATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH) 
load NCCL/2.19.4 (LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH) 
load GCC/11.4.0 (PATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH, HDF5_DIR, HDF5_ROOT) 
load BIN_UTILS/2.37 (PATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH, HDF5_DIR, HDF5_ROOT) 
load CUDA/12.1 (PATH, MANPATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH, CUDA_HOME, CUDA_VERSION, CUDA_INC, CUDA_INSTALL_PATH) 
load CUDNN/8.8/cuda12 (LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH, CUDNN_LIB_DIR, CUDNN_LIBRARY, CUDNN_INCLUDE_DIR) 
load TENSORRT/8.6/cuda12 (PATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH) 
2024-06-08 13:48:13.245769: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-08 13:48:13.292581: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512_FP16, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/apps/ACC/PYTHON/3.11.5/GCC/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2024-06-08 13:48:20.294330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 62623 MB memory:  -> device: 0, name: NVIDIA H100, pci bus id: 0000:1b:00.0, compute capability: 9.0
2024-06-08 13:48:20.295281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 62623 MB memory:  -> device: 1, name: NVIDIA H100, pci bus id: 0000:2c:00.0, compute capability: 9.0
2024-06-08 13:48:20.295855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 62623 MB memory:  -> device: 2, name: NVIDIA H100, pci bus id: 0000:9d:00.0, compute capability: 9.0
2024-06-08 13:48:20.296396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 62623 MB memory:  -> device: 3, name: NVIDIA H100, pci bus id: 0000:ad:00.0, compute capability: 9.0
/apps/ACC/PYTHON/3.11.5/GCC/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1717847304.695888  993107 service.cc:145] XLA service 0x7f127400a0d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1717847304.696021  993107 service.cc:153]   StreamExecutor device (0): NVIDIA H100, Compute Capability 9.0
I0000 00:00:1717847304.696026  993107 service.cc:153]   StreamExecutor device (1): NVIDIA H100, Compute Capability 9.0
I0000 00:00:1717847304.696560  993107 service.cc:153]   StreamExecutor device (2): NVIDIA H100, Compute Capability 9.0
I0000 00:00:1717847304.696569  993107 service.cc:153]   StreamExecutor device (3): NVIDIA H100, Compute Capability 9.0
2024-06-08 13:48:24.725532: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-06-08 13:48:24.859518: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8800
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1717847305.970159  993493 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_600', 408 bytes spill stores, 376 bytes spill loads

I0000 00:00:1717847305.970208  993417 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_614', 188 bytes spill stores, 188 bytes spill loads

I0000 00:00:1717847327.651514  993107 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
I0000 00:00:1717847346.017232  993850 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_788', 12 bytes spill stores, 12 bytes spill loads

I0000 00:00:1717847346.079187  993772 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_771', 24 bytes spill stores, 24 bytes spill loads

I0000 00:00:1717847346.163606  993731 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_600', 8 bytes spill stores, 8 bytes spill loads

I0000 00:00:1717847346.193580  993783 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_614', 28 bytes spill stores, 28 bytes spill loads

I0000 00:00:1717847346.196342  993791 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_788', 4 bytes spill stores, 4 bytes spill loads

I0000 00:00:1717847346.217070  993732 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_788', 12 bytes spill stores, 12 bytes spill loads

I0000 00:00:1717847346.242641  993851 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_614', 16 bytes spill stores, 16 bytes spill loads

I0000 00:00:1717847346.242654  993763 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_600', 196 bytes spill stores, 108 bytes spill loads

I0000 00:00:1717847346.251967  993757 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_614', 240 bytes spill stores, 240 bytes spill loads

I0000 00:00:1717847378.490528  994479 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_191', 4 bytes spill stores, 4 bytes spill loads

I0000 00:00:1717847378.568574  994497 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_184', 8 bytes spill stores, 8 bytes spill loads

I0000 00:00:1717847378.643397  994466 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_191', 28 bytes spill stores, 28 bytes spill loads

I0000 00:00:1717847378.778496  994477 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_191', 240 bytes spill stores, 240 bytes spill loads

Traceback (most recent call last):
  File "/gpfs/home/nct/nct01124/PRACTICA_2/model2.py", line 214, in <module>
    train_cnn()
  File "/gpfs/home/nct/nct01124/PRACTICA_2/model2.py", line 203, in train_cnn
    model.save(model_filename)
  File "/apps/ACC/PYTHON/3.11.5/GCC/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/apps/ACC/PYTHON/3.11.5/GCC/lib/python3.11/site-packages/keras/src/saving/saving_api.py", line 106, in save_model
    raise ValueError(
ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=MAMe_model_1.
